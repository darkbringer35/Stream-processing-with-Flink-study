# 8장 외부 시스템 연동
## 애플리케이션 일관성 보장
* exactly once를 보장하기 위해서는 소스 커넥터는 읽기 위치를 이전 체크포인트 위치로 재설정할 수 있어야 한다.
  * 파일 시스템
  * 카프카
* 애플리케이션이 읽기 위치를 저장하고 재설정할 수 없는 소스 커넥터에서 데이터를 가져온다면 데이터가 유실될 수 있다.
* end to end로 exactly once를 보장하고자 하면 싱크 커넥터가 멱등적 쓰기나 트랜잭션 쓰기를 보장해야 한다.

### 멱등성 쓰기
* 중복되는 연산이 한 번만 적용되게 하는 것

### 트랜잭션 쓰기
* 마지막 성공한 체크포인트의 계산 결과까지만 외부 싱크 시스템에 쓰는 것
* 플링크는 트랜잭션 싱크 커넥터를 구현하고자 WAL(write ahead log) 싱크와 2PC 싱크를 제공함
#### WAL 싱크
* 모든 결과 레코드를 애플리케이션의 상태에 쓰고 체크포인트 완료 알림을 받으면 싱크 시스템에 보내는 것 
* 모든 종류의 싱크 시스템과 함께 사용할 수 있음
* 완벽하게 exactly once를 보장할 수 없고 at least once를 보장함
* 애플리케이션 상태 크기가 커지는 문제가 있음
* 스파이크 쓰기 패턴(일시적으로 쓰기가 급상승하는 현상)을 처리할 수 있어야 함
#### 2PC 싱크
* 트랜잭션을 지원하거나 트랜잭션과 유사한 기능을 제공하는 싱크 시스템을 요구함
* 체크포인팅마다 싱크는 새 트랜잭션을 시작하고, 수신 레코드를 이 트랜잭션에 추가함

|        | 재설정 불가능한 소스  | 재설정 가능한 소스    |
|--------|--------------|---------------|
| 모든 싱크  | at most once | at least once |
| 멱등성 싱크 | at most once | exactly once  |
| WAL 싱크 | at most once | at least once |
| 2PC 싱크 | at most once | exactly once  |

## 기본 제공 커넥터
### 아파치 카프카 소스 커넥터
```scala
val properties = new Properties()
properties.setProperty("bootstrap.servers", "localhost:9092")
properties.setProperty("group.id", "test")

val stream: DataStream[String] = env.addSource(
    new FlinkKafkaConsumer[String](
        "topic",
        new SimpleStringSchema(),
        properties
    )
)
```
* 플링크 카프카 커넥터는 카프카 자체의 오프셋 추적 방식에 의존하지 않고, 체크포인트 오프셋을 통해 복구하고 읽음
* 카프카 파티션 중 하나가 비활성 상태가 되면 소스 인스턴스의 워터마크는 앞으로 진행되지 않게 되고 모든 애플리케이션을 정체시킨다.
* 애플리케이션 실행 초기에 어디서부터 파티션을 읽을 것이니지 시작 위치를 설정할 수 있음
  * FlinkKafkaConsumer.setStartFromGroupOffsets(): group.id로 설정한 컨슈머 그룹마다 알고 있는 마지막 읽기 위치
  * FlinkKafkaConsumer.setStartFromEarliest(): 파티션별로 가장 이른 오프셋
  * FlinkKafkaConsumer.setStartFromLatest(): 파티션별로 가능 최신 오프셋
  * FlinkKafkaConsumer.setStartFromTimestamp(long): 설정한 타임스탬프보다 더 큰 타임스탬프를 가진 모든 레코드
  * FlinkKafkaConsumer.setStartFromSpecificOffsets(Map): 특정 읽기 위치

### 아파치 카프카 싱크 커넥터
```scala
val stream: DataStream[String] = ...

val myProducer = new FlinkKafkaProducer[String](
        "Localhost:9092",
        "Topic"
        new SimpleStringSchema()
    )

stream.addSink(myProducer)
```

#### 카프카 싱크에 대한 at least once 일관성 보장
* 플링크 체크포인트를 활성화하고 애플리케이션의 모든 소스를 재설정할 수 있다.
* 싱크 커넥터는 쓰기가 성공하지 않으면 예외를 던져 애플리케이션을 중단시키고 복구하게 한다. (기본 설정)
  * retries 속성을 0(기본값) 이상의 값으로 설정해 카프카 클라이언트가 실패했다고 선언하기 전에 재시도할 횟수를 설정할 수 있다.
  * setLogFailureOnly(true)를 호출해 실패 시 로그만 남기도록 설정할 수 있다.
* 싱크 커넥터는 체크포인트가 완료되기 전에 쓰기 요청한 레코드에 대한 ACK가 오기를 기다린다. (기본 설정)
  * 싱크 객체의 setFlushOnCheckpoint(false)를 호출해서 기다리지 않도록 설정할 수 있다.

#### 카프카 싱크의 exactly once 보장
* FlinkKafkaProducer 생성자 파라미터 값으로 일관성 보장 설정을 할 수 있다.
  * Semantic.NONE: 일관성 보장하지 않음
  * Semantic.AT_LEAST_ONCE: 유실은 발생하지 않지만 중복이 될 수 있다.
  * Semantic.EXACTLY_ONCE: 카프카 트랜잭션 위에서 동작해 각 레코드를 단 한 번만 쓴다.
* 카프카의 트랜잭션 격리 수준을 컨슈머에서 read_committed로 하여 커밋된 메시지만 읽을 수 있음
* 열려있는 트랜잭션은 파티션 데이터를 읽는 모든 소비자에 지연을 발생시킬 수 있기 때문에 transaction.timeout.ms을 잘 설정해야 함
  * 플링크 카프카 싱크가 transaction.timeout.ms를 1시간으로 설정하는데, 카프카 브로커가 transaction.max.timeout.ms를 15분으로 설정하고 있기 때문에 이에 대한 조율이 필요하다.
* 유실이 발생할 수 있기 때문에 카프카 클러스터 acks 설정과 로그 설정을 신경 써야한다.
  * acks
  * log.flush.interval.messages
  * log.flush.interval.ms
  * log.flush.*

#### 사용자 정의 파티셔닝과 카프카 메시지에 타임스탬프 쓰기
* FlinkKafkaPartitioner를 직접 구현해서 파티셔닝을 조절할수 있음
* setWriteTimestampToKafka(true)를 호출하여 레크드의 이벤트 시간 타임스탬프를 카프카 메시지의 타임스탬프로 사용할 수 있음

### 파일 시스템 커넥터
* 스트리밍과 배치 애플리케이션을 연결할 때 많이 사용
* 아파치 파케이나 아파치 ORC 같은 고급 파일 형식과 함께 사용하면 아파치 Hive나 Impala 또는 Presto와 같은 분석 쿼리 엔진에서도 사용 가능하다.

```scala
val lineReader: new TextInputFormat(null)

val lineStream = DataStream[String] = env.readFile[String](
        lineReader,
        "hdfs:///path/to/my/data",
        FileProcessingMode.PROCESS_CONTINUOUSLY,
        30000L  // 감시 간격
    )
```

* 경로를 읽을 모드로, 모드는 PROCESS_ONCE, PROCESS_CONTINUOUSLY가 될 수 있다.
  * PROCESS_ONCE 모드는 잡이 시작될 떄 읽을 경로를 한 번만 스캔해 일치하는 파일을 읽는다.
    * PROCESS_ONCE는 어떤 체크포인팅도 수행핮 ㅣ 않는다.
  * PROCESS_CONTINUOUSLY는 경로를 주기적으로 스캔하고 새 파일이나 수정된 파일을 지속적으로 읽는다.
    * 파일 수정 시간을 기준으로 새 파일을 식별한다. 때문에 파일을 지속적으로 인입할 때 사용하는 방법은 임시 디렉터리에 파일을 쓰다가 완성되면 옮기는 형태이다.
* 감시 간격은 PROCESS_ONCE 모드에서 무시된다.
* FileInputFormat이 exactly once를 보장하려면 CheckpointableInputFormat를 구현해야 한다.
  * CheckpointableInputFormat을 구현하지 않을 경우 at least once 일관성만 보장하게 된다.
    * InputFormat이 마지막 체크포인트가 완료되었을 때 처리 중이던 스플릿을 처음부터 다시 읽기 때문이다.
* 파일 시스템 소스 커넥터는 이벤트 시간 애플리케이션에서 사용하고자 하면 어려움이 있을 수 있다.
  * 병렬 읽기 태스크는 파일 수정 시간 순서에 따라 입력 스플릿을 처리하기 때문이다.

### 파일 시스템 싱크 커넥터
```scala
val input: DataStream[String] = ...

val sink: StreamingFileSink[String] = StreamingFileSink
    .forRowFormat(
        new Path("/base/path),
        new SimpleStringEncoder[String]("UTF-8")
    )
    .build()

input.addSink(sink)
```

* StreamingFileSink는 애플리케이션이 정확히 한 번 체크포인트로 설정돼 있고 모든 입력 소스가 실패 시 재설정 가능하다면 애플리케이션에 단대단 정확히 한 번을 보장할 수 있다.
  * 파일을 진행 중, 보류 중, 종료와 같은 여러 단계로 관리하며 체크포인팅이 완료되어야 보류 중 파일을 종료 상태로 이동시킨다.
  * 보류 중 파일은 영윈히 커밋되지 않을 수 있고, 직접 정리해야 하는데 사용 중인지 커밋될 가능성이 있는지 파악이 필요하다.
* StreamingFileSink가 레코드를 받으면 어떤 버킷에 할당한다. 버킷은 시작 경로의 하위 디렉토리다.
* BucketAssinger가 버킷을 선택한다. 명시적으로 지정하지 않으면 처리 시간 기준으로 시간 단위 버킷에 할당하는 DateTimeBucketAssigner가 사용된다.
* 커밋된 파일의 ID는 연속적이지 않을 수 있기 때문에 유실을 의미하지 않는다.
  * 작업 중인 파일을 취소할 때 ID를 재사용핮 ㅣ않기 때문
* RollingPolicy는 태스크가 새로운 부분 파일을 언제 생성할지 결정한다.
  * 기본 설정은 128MB를 초가화거나 60초보다 오래된 경우 롤링을 유발한다.
* 인코딩은 row-encoding과 bluk-encoding 두 가지가 존재한다.
  * row-encoding: 모든 레코드를 개별적으로 인코딩하는 것
  * bluk-encoding: 레코드를 모아서 배치 방식으로 인코딩하는 것 (아파치 파케이에 필요하다)

### 아파치 카산드라 싱크 커넥터
* 카산드라는 기본 키를 기반으로 데이터를 모델링하고, 모든 쓰기 연산은 업서트로 동작한다.
* 정확히 한 번 체크포인트와 재설정 가능한 소스를 조합하면 업서트 쓰기로 궁극적인 exactly once를 보장할 수 있다.
* 플링크 카산드라 커넥터가 WAL을 사용하게 설정하면 비결정적인 로직을 사용하는 애플리케이션을 복구할 때 임시로 발생하는 불일치를 방지하고 정확히 한 번 출력을 제공한다.
```scala
val readings: DataStream[(String, Float)] = ...

val sinkBuilder: CassandraSinkBuilder[(String, Float)] = CassandraSink.addSink(readings)

sinkBuilder
    .setHost("localhost")
    .setQuery(
        "INSERT INTO example.sensors(sensorId, temperature) VALUES (?,?);"
    )
    .build()
```
* POJO 필드들은 순서가 정해져 있지 않으므로 sinkBuilder에 INSERT 쿼리를 지정하지 않는다.
* 대신 JPA같은 어노테이션을 달아야 한다.
* enableWriteAheadLog(\[CheckpoinCommiter\])로 비결정적인 애플리케이션 로직을 사용할 때 exactly once를 보장하는 WAL을 활성화 한다.

## 사용자 정의 소스 함수 구현
* SourceFunction: 병렬 소스 커넥터가 아닐 때
* ParallelSourceFunction: 병렬 소스 커넥터일 때
* 위 메서드들은 void run(SourceContext<T> ctx), void concel()을 구현해야 한다.
* 보통 데이터를 읽거나 수신하고 레코드를 내보내는 작업은 무한 루프로 실행된다. 구현에 따라 종료 조건을 명시할 수도 있다.
* 우아하게 종료하기 위해서는 cancel() 호출시 바로 run() 메서드가 종료될 수 있어야 한다.

```scala
class CountSource extends SourceFunction[Long] {
    var isRunning: boolean = true
    
    override def run(ctx: SourceFunction.SourceContext[Long]) = {
        var cnt: Long = -1
        while (isRunning && cnt < Long.MaxValue) {
            cnt += 1
            ctx.collect(cnt)
        }
    }
    
    override def cancel() = isRunning = false
}
```

### 재설정 가능한 소스 함수
* 재설정 가능한 소스 함수는 CheckpointedFunction 인터페이스를 구현해야 한다.
* 읽기 오프셋과 파일 경로나 파티션 ID 같은 모든 관련 메타데이터를 연산자의 리스트 상태나 리스트 상태에 저장해야 한다.
* SourceContext.getCheckpointLock() 메서드를 통해 락을 걸어서 CheckpointedFunction.snapshotState() 메서드가 호출되는 동안에는 읽기 오프셋을 앞으로 진행하거나 데이터를 내보내지 않는다.

```scala
class CountSource extends SourceFunction[Long] with CheckpointedFunction {
    var isRunning: boolean = true
    var cnt: Long = _
    var offsetState: ListState[Long] = _
    
    override def run(ctx: SourceFunction.SourceContext[Long]) = {
        while (isRunning && cnt < Long.MaxValue) {
            // 데이터 내보내기와 체크포인트를 동기화한다.
            ctx.getCheckpoinLock.synchronized {
                cnt += 1
                ctx.collect(cnt)
            }
        }
    }
    
    override def cancel() = isRunning = false
    
    override def snapshotState(snapshotCtx: FunctionSanpshotContext): Unit = {
        // 이전 cnt를 삭제한다.
        offsetState.clear()
        // 현재 cnt를 추가한다.
        offsetState.add(cnt)
    }
    
    override def initializeState(initCtx: FUnctionInitializationContext): Unit = {
        val desc = new ListStateDescriptor[Long]("offset", classOf[Long])
        offsetState = initCtx.getOperatiorStateStore.getListState(desc)
        //cnt 값을 초기화한다.
        val it = offsetState.get()
        
        cnt = if (null == it || !it.iterator().hasNext) {
            -1L
        } else {
            it.iterator().next()
        }
    }
}
```

### SourceFunction, 타임스탬프, 워터마크
* 소스 함수는 SourceContext 객체를 통해 타임스탬프를 할당하고 워터마크를 내보낸다.
  * def collectWithTimestamp(T record, long timestamp): Unit
  * def emitWatermark(Watermark watermark): Unit
* collectWithTimestamp는 타임스탬프와 함께 레코드를 내보내고 emitWatermark는 받은 워터마크를 내보낸다.
* 소스 함수는 파티션마다 독립적인 워터마크를 생성할 수 있어야 하고 항상 모든 파티션의 워터마크 중 가장 작은 값을 워터마크로 내보내야 한다.
* 소스 함수는 휴면 상태 스트림 파티션을 처리해야 하며 SourceContext.markAsTemporarilyIdle()을 호출하여 휴면 상태로 만들어 해당 파티션을 무시하게 할 수 있다.

## 사용자 정의 싱크 함수 구현
* SinkFunction 인터페이스는 void invoke(IN value, Context ctx) 메서드 하나만 제공한다.
```scala
// 리눅스에서 localhost:9191을 리슨하는 nc -l localhost 9191 명령을 우선적으로 실행해서 프로세스를 하나 실행해 두어야 함
val readings: DataStream[SensorReading] = ???

//센서 읽음 데이터를 소켓으로 쓴다.
readings.addSink(new SimpleSocketSink("localhost", 9191))
    .setParallelism(1)

class SimpleSocketSink(val host: String, val port: Int) extends RichSourceFunction[SensorReading] {
    var socket: Socket = _
    var writer: PrintStream = _
    
    override def open(config: Configuration): Unit = {
        socket = new Socket(InetAddress.getByName(host), port)
        writer = new PrintStream(socket.getOutputStream)
    }
    
    override def invoke(value: SensorReading, ctx: SinkFunction.Context[_]): Unit = {
        writer.println(value.toString)
        writer.flush()
    }
    
    override def close(): Unit = {
        writer.close()
        socket.close()
    }
}
```

### 멱등적 싱크 커넥터
* 두 조건을 충족하면 멱등적 싱크 커넥터를 구현할 수 있다. 
  * 결과 데이터는 결정적 키를 가졌다. 이 키에 대해 멱등적 쓰기를 수행할 수 있다. 애플리케이션에서 결정적 키는 센서의 ID와 매분에 해당하는 타임스탬프가 될 수 있다.
  * 관계형 데이터베이스 시스템이나 키-값 저장소처럼 외부 시스템이 키별 갱신을 지원한다.

### 트랜잭션 싱크 커넥터
* 트랜잭션 싱크를 쉽게 구현하기 위해 확장 가능한 템플릿 두 개를 제공한다.
  * 두 템플릿은 잡매니저에서 체크포인트 완료 알림을 받는 CheckpointListener 인터페이스를 구현한다.
  * GenericWriterAheadSink 템플릿은 체크포인팅마다 외부에 전송할 레코드를 모두 수집하고 싱크 태스크의 연산자 상태에 저장한다.
  * TwoPhaseCommitSinkFunction 템플릿은 외부 싱크 시스템의 트랜잭션 특징을 이용한다. 싱크가 관련 체크포인트의 완료 알림을 수신하면 현재 트랜잭션을 커밋한다.

#### GenericWriteAheadSink
* WAL 싱크가 레코드를 한 번 이상 내보내는 장애 상황이 발생할 수 있다. (at least once)
  * 원자성을 지원하지 않으면 체크포인트에 저장한 데이터를 쓰는 중에 일부는 저장되고 일부는 실패해서 처음부터 다시 쓰는 일이 발생할 수 있다.
* WAL 싱크의 체크포인트 커밋은 두 단계로 수행된다.
  * 싱크는 체크포인트가 커밋됐다는 정보를 영구적으로 저장하고, WAL에서 레코드들을 삭제한다.
* 커밋 정보를 플링크 애플리케이션 상태에 저장하는 것은 불가능하다.
  * 대신 외부 영구 저장소에 커밋한 체크포인트 정보를 저장하고 조회할 수 있는 CheckpointCommitter라는 컴포넌트에 의존한다.
* GenericWriteAheadSink 연산자를 확장하는 연산자는 세 가지 생성 파라미터를 제공해야 한다.
  * CheckpointCommitter
  * TypeSerializer
  * JobID
  * 추가적으로 WAL 연산자는 boolean sendValues(Iterable<IN> values, long chkpntId, long timestamp) 메서드를 구현해야 한다.
* GenericWriteAheadSink는 완료된 체크포인트에 있는 레코드들을 외부 저장 시스템에 쓸 떄 sendValues를 호출한다.

```scala
val readings: DataStream[SensorReading] = ???

readings.transform("WriteAheadSink", new SocketWriteAheadSink)

class StdOutWriteAheadSink extends GenericWriteAheadSink[SensorReading] (
        // 로컬 파일 시스템으로 체크포인트를 커밋하는 CheckpointCommitter
        new FileCheckpointCommitter(System.getProperty("java.io.tmpdir")),
        // 레코드 Serializer
        createTypeInformation[SensorReading]
            .createSerializer(new ExecutionConfig),
        // CheckpointCommitter가 사용하는 랜덤 JobID
        UUID.randomUUID.toString) {
    
    override def sendValues(
        readings: Iterable[SensorReading],
        checkpointId: Long,
        timestamp: Long): Booeal = {
        
        
        for (r <- readings.asScala) {
            // 표준 입출력
            println(r)
        }
        True
    }
}
```
* GenericWriteAheadSink가 장애 시 레코드를 한 번 이상 내보낼 수 있는 두 가지 실패 케이스
  * sendValues() 실행 중 실패할 때, 외부 싱크 시스템이 모든 레코드를 쓰거나 쓰지 않음을 자동으로 지원하지 않는다면 일부 레코드는 쓰고 일부는 쓰지 못한다.
  * 모든 레코드를 정확히 썻고 sendValues()도 true를 반환했지만, CheckpointComitter 호출 전에 프로그램이 실패하거나 CheckpointComitter가 체크포인트를 커밋하기 전에 실패하면 복구할 때 아직 커밋하지 않은 모든 레코드를 다시 쓸 것이다.
  * 카산드라 싱크 커넥터의 경우 upsert 쓰기를 수행하기 때문에 exactly once가 깨지지 않는다. (비결정적 키에서 싱크 커넥터를 보호할 수 있음)

#### TwoPhaseCommitSinkFunction
* 싱크 함수가 단대단 정확히 한 번 일관성을 보장하는지 여부는 상세 구현에 달려 있다.
* 2PC 프로토콜은 비용이 비싸지만 플링크 문맥상 체크포인트마다 한 번만 실행되기 때문에 오버헤드가 작다.
* 또한 WAL 방식과 달리 레코드를 상태에 모으지 않기 때문에 메모리를 적게 쓸 수 있다.
* 2PC 구현에 필요한 요구 사항은 다음과 같다.
  * 외부 싱크 시스템은 트랜잭션을 제공하거나 싱크가 외부 시스템을 대상으로 트랜잭션을 흉내낼 수 있어야 한다.
  * 체크포인팅 사이에는 트랜잭션을 열고 모든 레코드를 쓸 수 있어야 한다.
  * 트랜잭션은 체크포인트 완료 알림을 받기 전까지 커밋을 대기해야 한다.
  * 싱크는 프로세스 실패 후 트랜잭션을 복구할수 있어야 한다. 일부 싱크 시스템은 열려 있는 트랜잭션을 커밋하거나 중단할 떄 사용하는 트랜잭션 ID를 제공한다.
  * 트랜잭션 커밋은 멱등적 연산이어야 한다.
```scala
class TransactionFileSink(val targetPath: String, val tempPath: String) extends TwoPhaseCommitSinkFunction[(String, Double), String, Void] (
        createTypeInformation[String].createSerializer(new ExecutionConfig),
        createTypeInformation[Void].createSerializer(new ExecutionConfig)) {
    
    var transactionWriter: BufferedWriter = _
    
    override def beginTransaction(): String = {
        // 트랜잭션 파일 경로를 현재 시간과 태스크 인덱스로 만든다.
        val timeNow = LocalDateTime.now(ZoneId.of("UTC"))
            .format(DateTimeFormatter.ISO_LOCAL_DATE_TIME)
        val taskIdx = this.getRuntimeContext.getIndexOfThisSubtask
        val transactionFile = s"$timeNow-$taskIdx"
        
        // 트랜잭션 파일과 writer 생성
        val tFilePath = Paths.get(s"$tempPath/$transactionFile")
        Files.createFile(tFilePath)
        this.transactionWriter = Files.newBufferedWriter(tFilePath)
        println(s"Creating Transcation File: $tFilePath")
        // 이후 이 트랜잭션을 식별하기 위해 트랜잭션 파일 이름을 반환한다.
        transactionFile
    }
    
    // 레코드를 현재 트랜잭션 파일에 쓴다.
    override def invoke(transaction: String, value: (String, Double), context: Context[_]): Unit = {
        transactionWriter.write(value.toString)
        transactionWriter.write('\n')
    }
    
    // 현재 트랜잭션 파일을 flush하고 닫는다.
    overried def preCommit(transaction: String): Unit = {
        transactionWriter.flush()
        transactionWriter.close()
    }
    
    // 사전 커밋한 트랜잭션 파일을 최종 디렉터리로 옮겨 트랜잭션을 커밋한다.
    overried def commit(transaction: String): Unit = {
        val tFilePath = Paths.get(s"$tempPath/$transation")
        // 커밋이 멱등적임을 확신하기 위해 파일이 존재하는지 확인한다.
        if (Files.exists(tFilePath)) {
            val cFilePath = Paths.get(s"$targetPath/$transation")
            Files.move(tFilePath, cFilePath)
        }
    }
    
    // 트랜잭션 파일을 삭제해 트랜잭션을 중지한다.
    override def abort(transaction: String): Unit = {
        val tFilePath = Paths.get(s"$tempPath/$transation")
        if (Files.exists(tFilePath)) {
            Files.delete(tFilePath)
        }
    }
}
```
* TwoPhaseCommitSinkFunction\[IN, TXN, CONTEXT\]는 세 개의 타입 파라미터를 갖고 있다.
  * IN은 입력 레코드 타입을 지정한다.
  * TXN은 장애 시 트랜잭션을 식별하고 복구할 때 사용하는 트랜잭션 식별자를 정의한다.
  * CONTEXT는 선택 사항으로 사용자 정의 Context 타입이다.

## 비동기로 외부 시스템에 접근
* 아파치 플링크는 AsyncFunction을 제공해 원격 I/O 호출로 인한 지연 문제를 극복한다.
* AsyncFunction는 동시에 여러 쿼리를 전송하고 결과를 비동기적으로 처리한다.
  * 레코드 순서를 보장하거나
  * 쿼리 결과가 도착하는 순으로 레코드를 내보내 지연 시간을 줄이게 설정할 수 있다.
* 또한 AsyncFunction 체크포인트와 잘 통합되어 있다.
  * 체크포인팅할 때 입력 레코드가 쿼리 응답을 기다리고 있다면 해당 입력 레코드를 체크포인팅했다가 복구할 떄 쿼리를 반복 실행한다.
* 쿼리 결과가 도착하는 순으로 레코드를 내보내더라도 이 레코드가 워터마크를 추월하지 않도록 보장하기 때문에 이벤트 시간 처리에서도 잘 동작한다.
* AsyncFunction을 사용하려면 외부 시스템은 비동기 호출을 지원하는 클라이언트를 제공해야 한다.
  * 외부 시스템이 동기 클라이언트만 지원한다면 요청을 보내는 별도 스레드를 생성하고 직접 처리할 수 있다.

```scala
trait AsyncFunction [IN, OUT] extends Function {
    def asyncInvoke(input: IN, resultFuture: ResultFuture[OUT]): Unit
}
```
